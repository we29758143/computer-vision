2.2.1 Question
Q: Why might we be interested in both training accuracy and testing accuracy? What do these two numbers tell us about our current model?
A:
Training accuracy gives the result from our training data. However, testing accuracy gives the 
result from the data which did not use in training our model. Testing accuracy tells the model 
performance on unseen data. If we got a high trainging accuracy but low testing accuracy, which
means our model is overfitting. So it is important to evaluate both accuracy.

2.2.2 Question
Q: Try varying the model parameter for learning rate to different powers of 10 (i.e. 10^1, 10^0, 10^-1, 10^-2, 10^-3) and training the model. What patterns do you see and how does the choice of learning rate affect both the loss during training and the final model accuracy?
A:
Bigger learning rate -> Learn fast, loss might explod, jump between global minimum and local minimum, 
                        model diverge
Smaller learning rate -> Learn slow, converge slow, if learning is to slow, need more epoch to train model
A better way to train model is vary the learning rate during training. We choose a higher learning rate
at the begining stage, and choose a lower learning rate for latter stage.


2.2.3 Question
Q: Try varying the parameter for weight decay to different powers of 10: (10^0, 10^-1, 10^-2, 10^-3, 10^-4, 10^-5). How does weight decay affect the final model training and test accuracy?
A:
While choose decay to 10^0, the accuracy rate is 77%. Afterall, choosing the decay 10^-1 to 10^-5, the result
did not vary a lot. 
Decay will reduce the effect of last weight when we update it. To prevent the model overfitting, we choose a 
reasonable decay to train the model. The role of weight decay is to adjust the impact of model complexity on 
the loss function. It lower the model's complexity and model will fit to training data properly but prevent 
from overfitting.


2.3.1 Question
Q: Currently the model uses a logistic activation for the first layer. Try using all the other activation functions we programmed. How well do they perform? What's best?
A:
Linear   -> training accuracy: 0.911667,   test accuracy: 0.914900
Tanh     -> training accuracy: 0.924167,   test accuracy: 0.925300
RELU     -> training accuracy: 0.913917,   test accuracy: 0.919100
LRELU    -> training accuracy: 0.916150,   test accuracy: 0.920300
Logistic -> training accuracy: 0.883517,   test accuracy: 0.889300
Softmax  -> training accuracy: 0.316883,   test accuracy: 0.314800
Tanh gives the best performance.

2.3.2 Question
Q: Using the same activation, find the best (power of 10) learning rate for your model. What is the training accuracy and testing accuracy?
A:
Select Tanh as our first layer's activation function
learning rate: 1     ->   training accuracy: 0.898950,   test accuracy: 0.898500
learning rate: 0.1   ->   training accuracy: 0.960683,   test accuracy: 0.953700
learning rate: 0.01  ->   training accuracy: 0.924167,   test accuracy: 0.925300
learning rate: 0.001  ->  training accuracy: 0.844933m   test accuracy: 0.854600
We should choose learning to 0.1, which gives the best performance.


2.3.3 Question
Q: Right now the regularization parameter `decay` is set to 0. Try adding some decay to your model. What happens, does it help? Why or why not may this be?
A:
Select Tanh as our first layer's activation function
Decay:    10      -> training accuracy: 0.098717,  test accuracy: 0.098000
Decay:     1      -> training accuracy: 0.098717,  test accuracy: 0.098000
Decay:   0.1      -> training accuracy: 0.816450,  test accuracy: 0.827700
Decay:  0.01      -> training accuracy: 0.913767,  test accuracy: 0.914400
Decay: 0.001      -> training accuracy: 0.952683,  test accuracy: 0.947900
Decay:0.0001      -> training accuracy: 0.960583,  test accuracy: 0.953900
If we choose a larger decay, the weight will not be updated. This is because while we calculate Î”w_t, it subtract
the whole w_t. So the result is randomly gussing its label.
As we choose a smaller decay, the performance is getting better slowly. 


2.3.4 Question
Q: Modify your model so it has 3 layers instead of 2. The layers should be `inputs -> 64`, `64 -> 32`, and `32 -> outputs`. Also modify your model to train for 3000 iterations instead of 1000. Look at the training and testing accuracy for different values of decay (powers of 10, 10^-4 -> 10^0). Which is best? Why?
A:
Layer(inputs, 64, TANH),
Layer(64, 32, TANH),
Layer(32, outputs, SOFTMAX)
Decay:      1      -> training accuracy: 0.098717,  test accuracy: 0.098000
Decay:    0.1      -> training accuracy: 0.741700,  test accuracy: 0.748900
Decay:   0.01      -> training accuracy: 0.903167,  test accuracy: 0.905600
Decay:  0.001      -> training accuracy: 0.973667,  test accuracy: 0.965900
Decay: 0.0001      -> training accuracy: 0.984133,  test accuracy: 0.970700
While we set decay to 0.0001 is the best. Given a little penalty on the regularization can prevent data from overfitting also not
losing the information from the previous layer. In the result, the bigger the decay, the low performance of the model.


2.3.5 Question
Q: Modify your model so it has 4 layers instead of 2. The layers should be `inputs -> 128`, `128 -> 64`, `64 -> 32`, and `32 -> outputs`. Do the same analysis as in 2.3.4.
A:
Layer(inputs, 128, TANH),
Layer(128, 64, TANH),
Layer(64, 32, TANH),
Layer(32, outputs, SOFTMAX)
Decay:      1      -> training accuracy: 0.098717,  test accuracy: 0.098000
Decay:    0.1      -> training accuracy: 0.604367,  test accuracy: 0.613400
Decay:   0.01      -> training accuracy: 0.908950,  test accuracy: 0.912200
Decay:  0.001      -> training accuracy: 0.975467,  test accuracy: 0.967200
Decay: 0.0001      -> training accuracy: 0.984200,  test accuracy: 0.970400
In this case, as we add more layer on the model, we saw the performance is getting slightly better than 3 layers. That is to say
the data set is not complex and the model performance is good enough to deal with the prediction.

2.3.6 Question
Q: Use the 2 layer model with the best activation for layer 1 but linear activation for layer 2. Now implement the functions `l1_loss` and `l2_loss` and change the necessary code in `classifier.cpp` to use these loss functions. Observe the output values and accuracy of the model and write down your observations for both the loss functions compared to cross-entropy loss. P.S. L2 and L1 losses are generally used for regression, but this is a classification problem.
A:
batch = 128;
iters = 3000;
rate = 0.01;
momentum = .9;
decay = 0;
L1 loss : training accuracy: 0.816767,  test accuracy: 0.829200
L2 loss : training accuracy: 0.931717,  test accuracy: 0.931500
For classification problem, the last layer must be one hot to calculate each label's probability. Then use argmax to find out
the result. If we use L2 to compute loss. The output will have multiple local minimum, which is a non-convex problem. However, if 
we use cross entropy to compute loss. It is still a convex problem. While doing gradient descent, convex problem will gives a nice
converge property.
In this case, we know l1 and l2 loss mostly used in regression problem like predicting the house price, some numeric stats.
However, this is a classification problem, we should calculate the loss by using cross-entropy. Thus, the performance for using
l1 and l2 loss is worse than using cross entropy. Also, we should not choose the linear activation for the second layer. Linear
activation mostly used in predicting a value. To deal with classification problem, mostly used sigmoid or softmax.


3.2.1 Question
Q: How well does your network perform on the CIFAR dataset?
A:
Model description:

batch = 128;
iters = 3000;
rate = 0.01;
momentum = .9;
decay = 0.0;

Layer(inputs, 32, TANH),
Layer(32, 64, TANH),
Layer(64, 32, TANH),
Layer(32, outputs, SOFTMAX)
CROSS_ENTROPY}

training accuracy: 0.463640,  test accuracy: 0.445200
